srun: Step created for StepId=35643732.1
Initializing AMReX (25.02-8-gcebfb9e3f6f4)...
MPI initialized with 256 MPI processes
MPI initialized with thread support level 0
Initializing CUDA...
Multiple GPUs are visible to each MPI rank. This is usually not an issue. But this may lead to incorrect or suboptimal rank-to-GPU mapping.!
CUDA initialized with 256 devices.
AMReX (25.02-8-gcebfb9e3f6f4) initialized

 FFT size: 512 256 256  batch size: 10  # of proc. 256

    Warm-up: 0.259452892
    Test # 0: 0.009292963
    Test # 1: 0.007964947
    Test # 2: 0.007812762
    Test # 3: 0.0083944
    Test # 4: 0.008148052
    Test # 5: 0.007871997
    Test # 6: 0.008061074
    Test # 7: 0.007908457
    Test # 8: 0.008091884
    Test # 9: 0.008156238
  armex batched fft time: 0.0081702774

Total GPU global memory (MB) spread across MPI: [40326 ... 40326]
Free  GPU global memory (MB) spread across MPI: [8313 ... 9602]
[The         Arena] space (MB) allocated spread across MPI: [30244 ... 30244]
[The         Arena] space (MB) used      spread across MPI: [0 ... 0]
[The Managed Arena] space (MB) allocated spread across MPI: [8 ... 8]
[The Managed Arena] space (MB) used      spread across MPI: [0 ... 0]
[The  Pinned Arena] space (MB) allocated spread across MPI: [8 ... 8]
[The  Pinned Arena] space (MB) used      spread across MPI: [0 ... 0]
[The   Comms Arena] space (MB) allocated spread across MPI: [47 ... 69]
[The   Comms Arena] space (MB) used      spread across MPI: [0 ... 0]
AMReX (25.02-8-gcebfb9e3f6f4) finalized
